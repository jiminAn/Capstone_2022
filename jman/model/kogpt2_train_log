[?1049h[>4;2m[?1h=[?2004h[1;59r[?12h[?12l[22;2t[22;1t[27m[29m[m[38;5;188m[48;5;233m[H[2J[?25l[59;1H"run_auto_regressive.py" 64L, 2546C[1;1H[38;5;59m[48;5;233m  1 [m[38;5;188m[48;5;233m[38;5;110mimport[m[38;5;188m[48;5;233m os
[38;5;59m[48;5;233m  2 [m[38;5;188m[48;5;233m[38;5;110mimport[m[38;5;188m[48;5;233m numpy [38;5;103mas[m[38;5;188m[48;5;233m np
[38;5;59m[48;5;233m  3 [m[38;5;188m[48;5;233m[38;5;110mfrom[m[38;5;188m[48;5;233m tqdm [38;5;110mimport[m[38;5;188m[48;5;233m tqdm
[38;5;59m[48;5;233m  4 
  5 [m[38;5;188m[48;5;233m[38;5;110mimport[m[38;5;188m[48;5;233m torch
[38;5;59m[48;5;233m  6 [m[38;5;188m[48;5;233m[38;5;110mfrom[m[38;5;188m[48;5;233m torch.utils.data [38;5;110mimport[m[38;5;188m[48;5;233m dataloader
[38;5;59m[48;5;233m  7 [m[38;5;188m[48;5;233m[38;5;110mfrom[m[38;5;188m[48;5;233m dataloader.wellness [38;5;110mimport[m[38;5;188m[48;5;233m WellnessAutoRegressiveDataset
[38;5;59m[48;5;233m  8 [m[38;5;188m[48;5;233m[38;5;110mfrom[m[38;5;188m[48;5;233m kogpt2 [38;5;110mimport[m[38;5;188m[48;5;233m DialogKoGPT2
[38;5;59m[48;5;233m  9 [m[38;5;188m[48;5;233mos.environ[[38;5;107m"TOKENIZERS_PARALLELISM"[m[38;5;188m[48;5;233m] = [38;5;107m"false"[m[38;5;188m[48;5;233m
[38;5;59m[48;5;233m 10 
 11 [m[38;5;188m[48;5;233m[38;5;103mif[m[38;5;188m[48;5;233m __name__ == [38;5;107m'__main__'[m[38;5;188m[48;5;233m:
[38;5;59m[48;5;233m 12 [m[38;5;188m[48;5;233m    [38;5;244m#data_path = "../data/wellness_dialog_for_autoregressive_train.txt"[m[38;5;188m[48;5;233m
[38;5;59m[48;5;233m 13 [m[38;5;188m[48;5;233m    checkpoint_path =[38;5;107m"../checkpoint"[m[38;5;188m[48;5;233m
[38;5;59m[48;5;233m 14 [m[38;5;188m[48;5;233m    save_ckpt_path = f[38;5;107m"{checkpoint_path}/kogpt2-wellnesee-auto-regressive.pth"[m[38;5;188m[48;5;233m
[38;5;59m[48;5;233m 15 
 16 [m[38;5;188m[48;5;233m    n_epoch = [38;5;167m5[m[38;5;188m[48;5;233m
[38;5;59m[48;5;233m 17 [m[38;5;188m[48;5;233m    batch_size = [38;5;167m4[m[38;5;188m[48;5;233m      [38;5;244m# Î∞∞Ïπò ÏÇ¨Ïù¥Ï¶à[m[38;5;188m[48;5;233m
[38;5;59m[48;5;233m 18 [m[38;5;188m[48;5;233m    device = [38;5;107m"cuda"[m[38;5;188m[48;5;233m [38;5;103mif[m[38;5;188m[48;5;233m torch.cuda.is_available() [38;5;103melse[m[38;5;188m[48;5;233m [38;5;107m"cpu"[m[38;5;188m[48;5;233m
[38;5;59m[48;5;233m 19 [m[38;5;188m[48;5;233m    save_step = [38;5;167m100[m[38;5;188m[48;5;233m [38;5;244m# ÌïôÏäµ Ï†ÄÏû• Ï£ºÍ∏∞[m[38;5;188m[48;5;233m
[38;5;59m[48;5;233m 20 [m[38;5;188m[48;5;233m    learning_rate = [38;5;167m5e-5[m[38;5;188m[48;5;233m  [38;5;244m# Learning Rate[m[38;5;188m[48;5;233m
[38;5;59m[48;5;233m 21 
 22 [m[38;5;188m[48;5;233m    dataset= WellnessAutoRegressiveDataset()
[38;5;59m[48;5;233m 23 [m[38;5;188m[48;5;233m    train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=[38;5;222mTrue[m[38;5;188m[48;5;233m)
[38;5;59m[48;5;233m 24 
 25 [m[38;5;188m[48;5;233m    model = DialogKoGPT2()
[38;5;59m[48;5;233m 26 
 27 [m[38;5;188m[48;5;233m    loss_fct = torch.nn.CrossEntropyLoss(ignore_index=[38;5;167m3[m[38;5;188m[48;5;233m)
[38;5;59m[48;5;233m 28 [m[38;5;188m[48;5;233m    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
[38;5;59m[48;5;233m 29 
 30 [m[38;5;188m[48;5;233m    losses =[]
[38;5;59m[48;5;233m 31 [m[38;5;188m[48;5;233m    [38;5;103mfor[m[38;5;188m[48;5;233m epoch [38;5;103min[m[38;5;188m[48;5;233m [38;5;222mrange[m[38;5;188m[48;5;233m(n_epoch):
[38;5;59m[48;5;233m 32 [m[38;5;188m[48;5;233m[8Ccount = [38;5;167m0[m[38;5;188m[48;5;233m
[38;5;59m[48;5;233m 33 [m[38;5;188m[48;5;233m[8C[38;5;103mwith[m[38;5;188m[48;5;233m tqdm(total=[38;5;222mlen[m[38;5;188m[48;5;233m(train_loader), desc=f[38;5;107m"Train({epoch})"[m[38;5;188m[48;5;233m) [38;5;103mas[m[38;5;188m[48;5;233m pbar:
[38;5;59m[48;5;233m 34 [m[38;5;188m[48;5;233m[12C[38;5;103mfor[m[38;5;188m[48;5;233m i, data [38;5;103min[m[38;5;188m[48;5;233m [38;5;222menumerate[m[38;5;188m[48;5;233m(train_loader):
[38;5;59m[48;5;233m 35 [m[38;5;188m[48;5;233m[16Coptimizer.zero_grad()
[38;5;59m[48;5;233m 36 [m[38;5;188m[48;5;233m[16Cdata = torch.stack(data)  [38;5;244m# list of TensorÎ°ú Íµ¨ÏÑ±ÎêòÏñ¥ ÏûàÍ∏∞ ÎïåÎ¨∏Ïóê listÎ•º stackÏùÑ ÌÜµÌï¥[m[38;5;188m[48;5;233m[37;1H[38;5;59m[48;5;233m    [m[38;5;188m[48;5;233m[38;5;244m Î≥ÄÌôòÌï¥Ï§ÄÎã§.[m[38;5;188m[48;5;233m
[38;5;59m[48;5;233m 37 [m[38;5;188m[48;5;233m[16Cdata = data.transpose([38;5;167m1[m[38;5;188m[48;5;233m, [38;5;167m0[m[38;5;188m[48;5;233m)
[38;5;59m[48;5;233m 38 
 39 [m[38;5;188m[48;5;233m[16Coutputs = model(data, labels=data)
[38;5;59m[48;5;233m 40 [m[38;5;188m[48;5;233m[16C_, logits = outputs[:[38;5;167m2[m[38;5;188m[48;5;233m]
[38;5;59m[48;5;233m 41 
 42 [m[38;5;188m[48;5;233m[16C[38;5;244m# Shift so that tokens < n predict n[m[38;5;188m[48;5;233m
[38;5;59m[48;5;233m 43 [m[38;5;188m[48;5;233m[16Cshift_logits = logits[..., :-[38;5;167m1[m[38;5;188m[48;5;233m, :].contiguous()
[38;5;59m[48;5;233m 44 [m[38;5;188m[48;5;233m[16Cshift_labels = data[..., [38;5;167m1[m[38;5;188m[48;5;233m:].contiguous()
[38;5;59m[48;5;233m 45 
 46 [m[38;5;188m[48;5;233m[16Closs = loss_fct(shift_logits.view(-[38;5;167m1[m[38;5;188m[48;5;233m, shift_logits.size(-[38;5;167m1[m[38;5;188m[48;5;233m)), shift_labels.view(-[38;5;167m1[m[38;5;188m[48;5;233m))
[38;5;59m[48;5;233m 47 [m[38;5;188m[48;5;233m[16Closs.backward()
[38;5;59m[48;5;233m 48 [m[38;5;188m[48;5;233m[16Coptimizer.step()
[38;5;59m[48;5;233m 49 
 50 [m[38;5;188m[48;5;233m[16Closses.append(loss.item())
[38;5;59m[48;5;233m 51 
 52 [m[38;5;188m[48;5;233m[16C[38;5;103mif[m[38;5;188m[48;5;233m count % [38;5;167m10[m[38;5;188m[48;5;233m == [38;5;167m0[m[38;5;188m[48;5;233m:
[38;5;59m[48;5;233m 53 [m[38;5;188m[48;5;233m[20C[38;5;222mprint[m[38;5;188m[48;5;233m([38;5;107m'epoch no.{} train no.{}  loss = {}'[m[38;5;188m[48;5;233m.format(epoch, count + [38;5;167m1[m[38;5;188m[48;5;233m, loss))
[38;5;59m[48;5;233m 54 [m[38;5;188m[48;5;233m[16C[38;5;103mif[m[38;5;188m[48;5;233m (count > [38;5;167m0[m[38;5;188m[48;5;233m [38;5;103mand[m[38;5;188m[48;5;233m count % save_step == [38;5;167m0[m[38;5;188m[48;5;233m) [38;5;103mor[m[38;5;188m[48;5;233m ([38;5;222mlen[m[38;5;188m[48;5;233m(data) < batch_size):
[38;5;59m[48;5;233m 55 [m[38;5;188m[48;5;233m[20Ctorch.save({
[38;5;59m[48;5;233m 56 [m[38;5;188m[48;5;233m[24C[38;5;107m'epoch'[m[38;5;188m[48;5;233m: epoch,
[38;5;16m[48;5;253m 1:1 [Top]                                         ~/git/Capstone_2022/jman/model/run_auto_regressive.py\[1;5H[?25h[?25l[m[38;5;188m[48;5;233m[59;1HType  :qa  and press <Enter> to exit Vim[1;5H[?25h[?25l[?25h[?25l[?25h[?25l[?25h[?25l[?25h[?25l[?25h[?25l[?25h[?25l[?25h[?25l[?25h[?25l[?25h[59;1H[39;49m[?2004l[?1l>[>4;m[?1049lVim: Caught deadly signal HUP
Vim: Finished.
[59;1H[23;2t[23;1t[27m[29m[m[38;5;188m[48;5;233m[39;49m