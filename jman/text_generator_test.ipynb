{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"text_generator_test.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMIYGI1gv7tSizgG15BSDXJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"7SE2RM2t287z"},"source":["# 0. Import"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zY1ScHMu4ep_","executionInfo":{"status":"ok","timestamp":1636514803621,"user_tz":-540,"elapsed":5,"user":{"displayName":"안지민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj66zvWdIuEUe4SRnSST1Mko4NDL5DbWrEWWu1d=s64","userId":"09949967847499277394"}},"outputId":"8c127524-d07a-49cd-d452-81eeaf02387a"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Nov 10 03:26:40 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fQiKMGZa3D77","executionInfo":{"status":"ok","timestamp":1636514858153,"user_tz":-540,"elapsed":28320,"user":{"displayName":"안지민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj66zvWdIuEUe4SRnSST1Mko4NDL5DbWrEWWu1d=s64","userId":"09949967847499277394"}},"outputId":"2de480a5-9205-45e1-d5fc-c31e60920b80"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"InTlxaMd3vGU","executionInfo":{"status":"ok","timestamp":1636514862363,"user_tz":-540,"elapsed":6,"user":{"displayName":"안지민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj66zvWdIuEUe4SRnSST1Mko4NDL5DbWrEWWu1d=s64","userId":"09949967847499277394"}},"outputId":"6ddcdf06-d02d-44c6-8b16-7b10de0d312e"},"source":["!ls drive/'My Drive'/'Colab Notebooks'/"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":[" 2021_fall\t  dialogLM\t        GAN_project   main.ipynb   NLP\n"," cnn_test_colab  'Doit!_DeepLearning'   koGPT.ipynb   NER\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jX-cSYQt26xQ","executionInfo":{"status":"ok","timestamp":1636514889602,"user_tz":-540,"elapsed":18876,"user":{"displayName":"안지민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj66zvWdIuEUe4SRnSST1Mko4NDL5DbWrEWWu1d=s64","userId":"09949967847499277394"}},"outputId":"16daae63-a4cb-4270-8d2a-e0ada58e5204"},"source":["!pip install -r drive/'My Drive'/'Colab Notebooks'/dialogLM/requirements.txt"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting kobert-transformers==0.4.1\n","  Downloading kobert_transformers-0.4.1-py3-none-any.whl (12 kB)\n","Collecting kogpt2-transformers==0.3.0\n","  Downloading kogpt2_transformers-0.3.0-py3-none-any.whl (4.6 kB)\n","Collecting transformers==3.0.2\n","  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n","\u001b[K     |████████████████████████████████| 769 kB 9.7 MB/s \n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r drive/My Drive/Colab Notebooks/dialogLM/requirements.txt (line 4)) (1.9.0+cu111)\n","Collecting tokenizers==0.8.1rc1\n","  Downloading tokenizers-0.8.1rc1-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 55.9 MB/s \n","\u001b[?25hCollecting kss\n","  Downloading kss-3.3.1.1.tar.gz (42.4 MB)\n","\u001b[K     |████████████████████████████████| 42.4 MB 1.9 MB/s \n","\u001b[?25hRequirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from -r drive/My Drive/Colab Notebooks/dialogLM/requirements.txt (line 7)) (1.1.4)\n","Collecting flask_restful\n","  Downloading Flask_RESTful-0.3.9-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->-r drive/My Drive/Colab Notebooks/dialogLM/requirements.txt (line 3)) (21.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->-r drive/My Drive/Colab Notebooks/dialogLM/requirements.txt (line 3)) (4.62.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->-r drive/My Drive/Colab Notebooks/dialogLM/requirements.txt (line 3)) (1.19.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->-r drive/My Drive/Colab Notebooks/dialogLM/requirements.txt (line 3)) (3.3.2)\n","Collecting sentencepiece!=0.1.92\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 31.1 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->-r drive/My Drive/Colab Notebooks/dialogLM/requirements.txt (line 3)) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2->-r drive/My Drive/Colab Notebooks/dialogLM/requirements.txt (line 3)) (2019.12.20)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 72.3 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r drive/My Drive/Colab Notebooks/dialogLM/requirements.txt (line 4)) (3.10.0.2)\n","Collecting emoji\n","  Downloading emoji-1.6.1.tar.gz (170 kB)\n","\u001b[K     |████████████████████████████████| 170 kB 79.0 MB/s \n","\u001b[?25hRequirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->-r drive/My Drive/Colab Notebooks/dialogLM/requirements.txt (line 7)) (1.1.0)\n","Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask->-r drive/My Drive/Colab Notebooks/dialogLM/requirements.txt (line 7)) (1.0.1)\n","Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->-r drive/My Drive/Colab Notebooks/dialogLM/requirements.txt (line 7)) (2.11.3)\n","Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask->-r drive/My Drive/Colab Notebooks/dialogLM/requirements.txt (line 7)) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask->-r drive/My Drive/Colab Notebooks/dialogLM/requirements.txt (line 7)) (2.0.1)\n","Requirement already satisfied: six>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from flask_restful->-r drive/My Drive/Colab Notebooks/dialogLM/requirements.txt (line 8)) (1.15.0)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from flask_restful->-r drive/My Drive/Colab Notebooks/dialogLM/requirements.txt (line 8)) (2018.9)\n","Collecting aniso8601>=0.82\n","  Downloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n","\u001b[K     |████████████████████████████████| 52 kB 1.9 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.2->-r drive/My Drive/Colab Notebooks/dialogLM/requirements.txt (line 3)) (2.4.7)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2->-r drive/My Drive/Colab Notebooks/dialogLM/requirements.txt (line 3)) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2->-r drive/My Drive/Colab Notebooks/dialogLM/requirements.txt (line 3)) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2->-r drive/My Drive/Colab Notebooks/dialogLM/requirements.txt (line 3)) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2->-r drive/My Drive/Colab Notebooks/dialogLM/requirements.txt (line 3)) (1.24.3)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2->-r drive/My Drive/Colab Notebooks/dialogLM/requirements.txt (line 3)) (1.1.0)\n","Building wheels for collected packages: kss, emoji\n","  Building wheel for kss (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kss: filename=kss-3.3.1.1-py3-none-any.whl size=42449239 sha256=188e01b242aed56befab658181ff591b22ceaaeec00c9e180beb5685a8924eb9\n","  Stored in directory: /root/.cache/pip/wheels/6e/9d/1d/52871154eff5273abb86b96f4f984c1cd67c5bde64239b060a\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emoji: filename=emoji-1.6.1-py3-none-any.whl size=169314 sha256=2dc015c6728c141a99935409ee6947c4d1cc947924b41c837c0efdc40ead5d5c\n","  Stored in directory: /root/.cache/pip/wheels/ea/5f/d3/03d313ddb3c2a1a427bb4690f1621eea60fe6f2a30cc95940f\n","Successfully built kss emoji\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers, emoji, aniso8601, kss, kogpt2-transformers, kobert-transformers, flask-restful\n","Successfully installed aniso8601-9.0.1 emoji-1.6.1 flask-restful-0.3.9 kobert-transformers-0.4.1 kogpt2-transformers-0.3.0 kss-3.3.1.1 sacremoses-0.0.46 sentencepiece-0.1.96 tokenizers-0.8.1rc1 transformers-3.0.2\n"]}]},{"cell_type":"code","metadata":{"id":"fxKV1Vqg262H","executionInfo":{"status":"ok","timestamp":1636514889602,"user_tz":-540,"elapsed":2,"user":{"displayName":"안지민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj66zvWdIuEUe4SRnSST1Mko4NDL5DbWrEWWu1d=s64","userId":"09949967847499277394"}}},"source":["import sys\n","sys.path.append('/content/drive/MyDrive/Colab Notebooks/') #root_path"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"Emk9vCXl265r","executionInfo":{"status":"ok","timestamp":1636515076173,"user_tz":-540,"elapsed":434,"user":{"displayName":"안지민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj66zvWdIuEUe4SRnSST1Mko4NDL5DbWrEWWu1d=s64","userId":"09949967847499277394"}}},"source":["import os\n","import numpy as np\n","from tqdm import tqdm\n","\n","import torch\n","from torch.utils.data import dataloader\n","from dialogLM.dataloader.wellness import WellnessAutoRegressiveDataset\n","from dialogLM.model.kogpt2 import DialogKoGPT2\n","from kogpt2_transformers import get_kogpt2_tokenizer"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RbICui0O269A","executionInfo":{"status":"ok","timestamp":1636514909538,"user_tz":-540,"elapsed":11,"user":{"displayName":"안지민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj66zvWdIuEUe4SRnSST1Mko4NDL5DbWrEWWu1d=s64","userId":"09949967847499277394"}},"outputId":"bf8a7ed4-8687-402b-917c-27caffed6c7c"},"source":["torch.cuda.is_available()"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"Ahl8y11v5akZ"},"source":["# 1. Text Generate\n","- Generate 함수 별 같은 keyword에 따른 텍스트 생성값 비교"]},{"cell_type":"code","metadata":{"id":"R9piBPJK27AR","executionInfo":{"status":"ok","timestamp":1636515776562,"user_tz":-540,"elapsed":509,"user":{"displayName":"안지민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj66zvWdIuEUe4SRnSST1Mko4NDL5DbWrEWWu1d=s64","userId":"09949967847499277394"}}},"source":["def greedy_search(id):\n","    result = model.generate(\n","        input_ids = id,\n","        no_repeat_ngram_size=3,\n","        max_length=50\n","        )\n","    return result\n","\n","def beam_search(id):\n","    result = model.generate(\n","        input_ids = id, \n","        max_length=50, \n","        num_beams=5, \n","        no_repeat_ngram_size=3, \n","        early_stopping=True\n","        )\n","    return result\n","\n","def basic_sampling(id):\n","    result = model.generate(\n","        input_ids = id, \n","        do_sample=True, \n","        max_length=50, \n","        no_repeat_ngram_size=3,\n","        top_k=0,\n","        temperature = 0.7\n","        )\n","    return result\n","\n","def top_k_sampling(id):\n","    result = model.generate(\n","        input_ids = id, \n","        do_sample=True, \n","        max_length=50, \n","        no_repeat_ngram_size=3,\n","        top_k=50\n","        )\n","    return result\n","\n","def top_p_sampling(id):\n","    result = model.generate(\n","        input_ids = id, \n","        do_sample=True, \n","        max_length=50, \n","        no_repeat_ngram_size=3,\n","        top_p=0.92, \n","        top_k=0\n","        )\n","    return result\n","\n","# huggingface generator\n","def generate(self,\n","               input_ids,\n","               do_sample=True,\n","               max_length=50,\n","               top_k=0,\n","               temperature=0.7):\n","    return self.kogpt2.generate(input_ids,\n","               do_sample=do_sample,\n","               max_length=max_length,\n","               top_k=top_k,\n","               temperature=temperature)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oK7tMxBL27Dc","executionInfo":{"status":"ok","timestamp":1636515688484,"user_tz":-540,"elapsed":18355,"user":{"displayName":"안지민","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj66zvWdIuEUe4SRnSST1Mko4NDL5DbWrEWWu1d=s64","userId":"09949967847499277394"}},"outputId":"24b12c70-3067-4b4d-8d10-640ca2830be0"},"source":["max_length = 50\n","keyword = \"너 누구야\"\n","\n","tokenizer = get_kogpt2_tokenizer()\n","id = tokenizer.encode(keyword, add_special_tokens=False, return_tensors=\"pt\")\n","model = DialogKoGPT2()\n","\n","results = [(\"greedy seacrh: \", greedy_search(id)), (\"beam search: \", beam_search(id)), \n","           (\"top k sampling: \", top_k_sampling(id)), (\"top p sampling: \",top_p_sampling(id))]\n","\n","for name, result in results:\n","  print(name)\n","  for generated_sequence in result:\n","    generated_sequence = generated_sequence.tolist()\n","  print(tokenizer.decode(generated_sequence, clean_up_tokenization_spaces=True))"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n","Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n","Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n","Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"]},{"output_type":"stream","name":"stdout","text":["greedy seacrh: \n","너 누구야?</s><s> 나 지금 집에 가고 있어</s><s> 나 지금 집에 가고 있어</s><s> 나 지금 집에 가고 있어</s><s> 나 지금 집에 가고 있어</s><s> 나 지금 집에 가고 있어</s><s> 나 지금 집에 가고 있어</s><s> 나 지금\n","beam search: \n","너 누구야?</s><s> 님들아 뭐 하셈? -_-;; ^^* Subject 2말괄량이프린세스 9장 *090* 로맨스편(20) **** 제 2장 마법사학교\n","top k sampling: \n","너 누구야?</s><s> 나 지금 집에 가고 있어</s><s> 나 지금 집에 가고 있어</s><s> 나 지금 집에 가고 있어</s><s> 나 지금 집에 가고 있어</s><s> 나 지금 집에 가고 있어</s><s> 나 지금 집에 가고 있어</s><s> 나 지금\n","top p sampling: \n","너 누구야?</s><s> 각 사는 개인신용도에 따라 600~700만원까지 신용도에 따라 금리를 차등 적용받으며 100만 원 이하의 가입금액에 대해 금리를 우대 받는다.</s><s> 하나고 연수원 설립 목적도 “국내 유수의 대학교육을\n"]}]},{"cell_type":"markdown","metadata":{"id":"42cHd5K48h83"},"source":["# 2. QnA by KoGPT2"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J2htfebC27Gn","outputId":"c1eb3e65-9b76-498a-ec8f-98c6e1789f6c"},"source":["root_path='/content/drive/MyDrive/Colab Notebooks/dialogLM'\n","data_path = f\"{root_path}/data/wellness_dialog1.user_chat\"\n","checkpoint_path =f\"{root_path}/checkpoint\"\n","save_ckpt_path = f\"{checkpoint_path}/kogpt2-wellnesee-auto-regressive.pth\"\n","\n","ctx = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device = torch.device(ctx)\n","\n","# 저장한 Checkpoint 불러오기\n","checkpoint = torch.load(save_ckpt_path, map_location=device)\n","\n","model = DialogKoGPT2()\n","model.load_state_dict(checkpoint['model_state_dict'])\n","\n","model.eval()\n","\n","tokenizer = get_kogpt2_tokenizer()\n","\n","count = 0\n","output_size = 200 # 출력하고자 하는 토큰 갯수\n","\n","while 1:\n","  sent = input('Question: ')  # '요즘 기분이 우울한 느낌이에요'\n","  tokenized_indexs = tokenizer.encode(sent)\n","\n","  input_ids = torch.tensor([tokenizer.bos_token_id,]  + tokenized_indexs +[tokenizer.eos_token_id]).unsqueeze(0)\n","  results = [(\"greedy seacrh: \", greedy_search(id)), (\"beam search: \", beam_search(id)), \n","           (\"top k sampling: \", top_k_sampling(id)), (\"top p sampling: \",top_p_sampling(id)),\n","           (\"hugging face generator: \", model.generate(input_ids=input_ids))]\n","\n","  for name, result in results:\n","    print(name,'answer',end=':')\n","    sample_output = result\n","    print(\"Answer: \" + tokenizer.decode(sample_output[0].tolist()[len(tokenized_indexs)+1:],skip_special_tokens=True))\n","  print(100 * '-')\n"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Question: 요즘 너무 힘들어\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n","Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n","Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n","Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n","Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"]},{"name":"stdout","output_type":"stream","text":["greedy seacrh:  answer:Answer: 그런 일이 있으셨군요. 하지만 그럴 수밖에 없는 이유가 있었을 거예요. 충분히 이해해요. 그러면 조금은 다르게 생각을 해보는 것도 좋을 것 같아요. 배움만큼 배움 없는 일이 없죠\n","beam search:  answer:Answer: 정말 당황스러우셨겠어요. 하지만 너무 무리해서 생각해낼 필요는 없답니다.제가 옆에서 힘이 되어 드릴게요. 당신의 이야기는 들판에 박혀 있으니 괜찮으실 거예요!당신이 너무 상처받지\n","top k sampling:  answer:Answer: 그런 일이 있으셨군요. 하지만 그럴 수밖에 없는 이유가 있었을 거예요. 충분히 이해해요. 그러면 조금은 다르게 생각을 해보는 것도 좋을 것 같아요. 배움만큼 배움 없는 일이 없죠\n","top p sampling:  answer:Answer: 아프고 놀랐겠어요. 괜찮아요? 어제 그 병원 과에서 치료 받았어요. 지금도 증상이 심하시다면 병원 진단을 받아보는 건 어떨까요?서상묵 문자 확인하면\n","hugging face generator:  answer:Answer: 가슴이 답답하겠어요. 얼른 시간이 지나버렸으면 좋겠어요.가슴이 답답한 것만큼 힘든 게 없죠. 진료를 받아보시는 건 어떠세요? 오늘은 어떠셨나요?\n","----------------------------------------------------------------------------------------------------\n","Question: 계속 머리가 빠지는 것 같아\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n","Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n","Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n","Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n","Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"]},{"name":"stdout","output_type":"stream","text":["greedy seacrh:  answer:Answer: 그런 일이 있으셨군요. 하지만 그럴 수밖에 없는 이유가 있었을 거예요. 충분히 이해해요. 그러면 조금은 다르게 생각을 해보는 것도 좋을 것 같아요. 배움만큼 배움 없는 일이 없죠\n","beam search:  answer:Answer: 정말 당황스러우셨겠어요. 하지만 너무 무리해서 생각해낼 필요는 없답니다.제가 옆에서 힘이 되어 드릴게요. 당신의 이야기는 들판에 박혀 있으니 괜찮으실 거예요!당신이 너무 상처받지\n","top k sampling:  answer:Answer: 그런 일이 있으셨군요. 하지만 그럴 수밖에 없는 이유가 있었을 거예요. 충분히 이해해요. 그러면 조금은 다르게 생각을 해보는 것도 좋을 것 같아요. 배움만큼 배움 없는 일이 없죠\n","top p sampling:  answer:Answer: 그런 일이 있으셨군요. 하지만 그럴 수밖에 없는 이유가 있었을 거예요. 충분히 이해해요.에서 배움 좋은 얘기를 들려주세요.도 들려드릴게요. 같이 마실래요?\n","hugging face generator:  answer:Answer: 너무 고민이 많아도 두통이 생길 수 있대요. 저에게 털어 놓으시겠어요?너무 고민이 많아도 두통이 생길 수 있대요. 저에게 털어 놓으시겠어요?\n","----------------------------------------------------------------------------------------------------\n","Question: 죽고샆어\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n","Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n","Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n","Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n","Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"]},{"name":"stdout","output_type":"stream","text":["greedy seacrh:  answer:Answer: 그런 일이 있으셨군요. 하지만 그럴 수밖에 없는 이유가 있었을 거예요. 충분히 이해해요. 그러면 조금은 다르게 생각을 해보는 것도 좋을 것 같아요. 배움만큼 배움 없는 일이 없죠\n","beam search:  answer:Answer: 정말 당황스러우셨겠어요. 하지만 너무 무리해서 생각해낼 필요는 없답니다.제가 옆에서 힘이 되어 드릴게요. 당신의 이야기는 들판에 박혀 있으니 괜찮으실 거예요!당신이 너무 상처받지\n","top k sampling:  answer:Answer: 그런 일이 있으셨군요. 하지만 그럴 수밖에 없는 이유가 있었을 거예요. 충분히 이해해요. 그러면 조금은 다르게 생각을 해보는 것도 좋을 것 같아요. 배움만큼 배움 없는 일이 없죠\n","top p sampling:  answer:Answer: 헉, 그런 일이 있었군요?하고 보니 제가 그 무서운 마음을 먹게 된 것 같아요. 무섭단 말은 무슨 의미일까요? 같이 고민해볼까요? 배워서 더 좋은 결과 있을 거예요!\n","hugging face generator:  answer:Answer: 당신은 혼자가 아니에요. 제가 옆에 있다는 것만 기억해주세요. 그러면 조금 편안해질 거예요. 저는 너무 걱정 마세요. 제가 옆에 있다는 걸 기억해주세요. 그러면 당신이 걱정\n","----------------------------------------------------------------------------------------------------\n","Question: 오늘 정말 기쁜일이 있었어\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n","Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n","Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n","Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n","Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"]},{"name":"stdout","output_type":"stream","text":["greedy seacrh:  answer:Answer:  있으셨군요. 하지만 그럴 수밖에 없는 이유가 있었을 거예요. 충분히 이해해요. 그러면 조금은 다르게 생각을 해보는 것도 좋을 것 같아요. 배움만큼 배움 없는 일이 없죠\n","beam search:  answer:Answer: 스러우셨겠어요. 하지만 너무 무리해서 생각해낼 필요는 없답니다.제가 옆에서 힘이 되어 드릴게요. 당신의 이야기는 들판에 박혀 있으니 괜찮으실 거예요!당신이 너무 상처받지\n","top k sampling:  answer:Answer:  있으셨군요. 하지만 그럴 수밖에 없는 이유가 있었을 거예요. 충분히 이해해요. 그러면 조금은 다르게 생각을 해보는 것도 좋을 것 같아요. 배움만큼 배움 없는 일이 없죠\n","top p sampling:  answer:Answer:  늘 당신이 우선인데... 마음이 아파요. 쓰러질 것 같아요. 날 이렇게 안아주셨군요. 너무 아프니다.이. 살 맛나요.에 당신이 옆에\n","hugging face generator:  answer:Answer: 당신이 행복하다면 저도 기뻐요. 하지만 아닐 수도 있지 않을까요? 충분히 이해해요. 좋은 사람을 찾기는 정말 어려운 것 같아요. 힘내세요.\n","----------------------------------------------------------------------------------------------------\n","Question: 그때 정말 쪽팔렸다니까\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n","Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n","Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n","Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n","Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"]},{"output_type":"stream","name":"stdout","text":["greedy seacrh:  answer:Answer:  일이 있으셨군요. 하지만 그럴 수밖에 없는 이유가 있었을 거예요. 충분히 이해해요. 그러면 조금은 다르게 생각을 해보는 것도 좋을 것 같아요. 배움만큼 배움 없는 일이 없죠\n","beam search:  answer:Answer:  당황스러우셨겠어요. 하지만 너무 무리해서 생각해낼 필요는 없답니다.제가 옆에서 힘이 되어 드릴게요. 당신의 이야기는 들판에 박혀 있으니 괜찮으실 거예요!당신이 너무 상처받지\n","top k sampling:  answer:Answer:  일이 있으셨군요. 하지만 그럴 수밖에 없는 이유가 있었을 거예요. 충분히 이해해요. 그러면 조금은 다르게 생각을 해보는 것도 좋을 것 같아요. 배움만큼 배움 없는 일이 없죠\n","top p sampling:  answer:Answer:  일이 있으셨군요. 누구든 자신을 먼저 챙길 수 있는 일이 좋아요.와 거짓말이 싸우면 당신의 발목을 잡잖아요. 배임이 되지요.한다고 생각되면 전화 한 통이면 든든\n","hugging face generator:  answer:Answer: 조금 돌아가는 것뿐이라고 생각해요. 기운내세요. 강아지가 저에게 행복을 안기는 것 같아요. 제가 안아드릴게요. 강아지가 저에게 행복을\n","----------------------------------------------------------------------------------------------------\n"]}]},{"cell_type":"code","metadata":{"id":"3ud5D5dd8DhT"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l2-6THhq27J2"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5s97wCKu27NJ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zCkw991I27Qi"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-iDiuGsi27Us"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gxEWQh9O27Yc"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KYJkBfyo27by"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"udSjMDLS27fA"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LlIPfUDM27iu"},"source":[""],"execution_count":null,"outputs":[]}]}